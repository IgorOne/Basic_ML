{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "tweets = pandas.DataFrame.from_csv(\"Tweets data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Sentiment                                      SentimentText\n",
      "ItemID                                                              \n",
      "1               0                       is so sad for my APL frie...\n",
      "5002            1       very very very happy and slightly skinny  xx\n",
      "10012           1  &quot;I feel better now, better than James Bro...\n",
      "15012           1  ...what can I say ....what a surprise...http:/...\n",
      "20012           0                                     @ ponyp: hey! \n",
      "25012           1       @404world yes I'm going to find one..pronto \n",
      "30012           0  @AdamJonesey mmm id love some parma violets ri...\n",
      "35012           1  @AlTheYid Roast beef and wasabi... yummmmmmmmm...\n",
      "40012           0  @amandafortier ahhh. yeah. kinda. I tweet from...\n",
      "45012           0                 @antdeshawn ... the pain is worst \n",
      "50012           1  @Ashtarte Just be your usual supportive self. ...\n",
      "55012           0  @azizabatini86 and that's fine--u kno, the dry...\n",
      "60012           0       @Bellemorda I miss you!!! Get back on soon. \n",
      "65012           0  @BrandyWandLover yer so was i hun. sum guy was...\n",
      "70012           0  @Andreicaaat Aww damn I can watch your vid on ...\n",
      "75012           1                      @anorangegal You've got mail \n",
      "80012           1  @cantyka hallo juga  thanks ya udah di follow....\n",
      "85012           0  @cbhamby easy there tiger...you should have co...\n",
      "90012           1  @clickjow depois tu pode ver outras s�ries. te...\n",
      "95012           0  @cianw I've never really been able to eat muss...\n"
     ]
    }
   ],
   "source": [
    "print(tweets[::5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "Извлечём из твитов признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = tweets[\"SentimentText\"]\n",
    "Y = tweets[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    text = <приведите текст к нижнему регистру>\n",
    "    \n",
    "    #<для начала будем использовать частоты букв как признаки>\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"    \n",
    "    for l in letters:\n",
    "        features.append(text.count(l))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a model\n",
    "Научим на наших признаках простую линейную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#порежем данные\n",
    "X_train = X[:70000]\n",
    "Y_train = Y[:70000]\n",
    "X_test = X[70000:]\n",
    "Y_test = Y[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите логистическую регрессию>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opinion mining\n",
    "\n",
    "Давайте использовуем нашу модель чтобы понять, что людям сейчас нравится/не нравится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "with open(\"testdata.txt\") as fin:\n",
    "    test_tweets = fin.read()[:-1].split('\\n')\n",
    "test_tweets = numpy.array(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\" I don\\'t care what anyone says, I like Hillary Clinton.'\n",
      " 'have an awesome time at purdue!..'\n",
      " \"Yep, I'm still in London, which is pretty awesome: P Remind me to post the million and one pictures that I took when I get back to Markham!...\"\n",
      " \"Have to say, I hate Paris Hilton's behavior but I do think she's kinda cute..\"\n",
      " 'i will love the lakers.']\n"
     ]
    }
   ],
   "source": [
    "print test_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ops = []\n",
    "for tweet in test_tweets:\n",
    "    X_ops.append(extract_features(tweet))\n",
    "X_ops = numpy.array(X_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiments = <предскажите эмоциональную окраску x_ops>\n",
    "sentiment_order = numpy.argsort(-sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### теперь посмотрим на наиболее любимые/ненавистные людям вещи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_ids = sentiment_order[:10]\n",
    "\n",
    "for tweet, score in zip(test_tweets[best_ids], sentiments[best_ids]):\n",
    "    print score,':',tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worst_ids = sentiment_order[-10:]\n",
    "\n",
    "for tweet, score in zip(test_tweets[worst_ids], sentiments[worst_ids]):\n",
    "    print score,':',tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_words = <список всех слов во всех твитах>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = list(set(words))\n",
    "word_to_id = {word:i for i,word in enumerate(list(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#выделите 1000 cлов, которые имеют наиболее разную вероятность войти в позитивный и негативный твит\n",
    "bag_of_words = <слова-признаки>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    words = filter(len,text.lower().split())\n",
    "    \n",
    "    <bag of words для слов>\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите модель>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collocations\n",
    "Найдём наиболее частые коллокации и используем их как признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9b287482a7a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcfinder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollocations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBigramCollocationFinder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcfinder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_freq_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmeasure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollocations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBigramAssocMeasures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_freq\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_words' is not defined"
     ]
    }
   ],
   "source": [
    "cfinder = collocations.BigramCollocationFinder.from_words(text_words)\n",
    "cfinder.apply_freq_filter(5)\n",
    "measure = collocations.BigramAssocMeasures.raw_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cfinder.nbest(measure,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    <bag of words для коллокаций>\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите модель>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
